## 训练策略

关于我们的数据，数据集原本是底下这个样子，从19XX(我忘了具体多少年)到2022年，然后没有划分test和eval的，反正考虑是随机拿几个编号的台风来当evaluation即可，在数据集里面的这些都是按照时序排列好了的，我们只需要随机选择非首尾的一个时刻（保证存在连续三张）就能完美解决问题。

```
data/
└── WP/ # west pacific ocean
    ├── image/                    # 台风图像数据
    │   ├── 202107/              # 年份+月份目录
    │   │   ├── 2021071900-202107-HMW8-1.h5  # 台风图像文件
    │   │   ├── 2021071901-202107-HMW8-1.h5
    │   │   └── ...
    │   ├── 202108/
    │   └── ...
    ├── metadata/                 # 元数据目录
    ├── aux_data.csv             # 辅助数据文件
    └── metadata.json            # 元数据配置文件
```

#### **步骤 A：训练判别器 (D)**

在这一步，**生成器的权重是固定的（冻结的）**，我们只更新两个判别器 `Ds` 和 `Dt` 的权重。目标是让它们更擅长区分真实图像和生成器生成的假图像。

1.  **准备数据**:
    *   从数据加载器中获取一批连续三帧的低分辨率 `(lr_t-1, lr_t, lr_t+1)` 和高分辨率 `(hr_t-1, hr_t, hr_t+1)` 图像。为了简化，我们主要关注中间帧 `t`。

2.  **生成假图像**:
    *   将低分辨率图像 `(lr_t-1, lr_t, lr_t+1)` 输入**生成器G**，得到三张超分辨率（SR）的假图像 `(sr_t-1, sr_t, sr_t+1)`。
    *   `sr_t = G(lr_t)` (这里的G是固定的，不计算梯度)

3.  **训练空间判别器 (Ds)**:
    *   **对真实图像打分**: 将**真实**的高分辨率图像 `hr_t` 和对应的低分辨率图像 `lr_t` 输入 `Ds`。`Ds` 的目标是输出 1 (表示“真实”)。计算 `Ds` 在真实图像上的损失（例如，与标签1的二元交叉熵损失）。
    *   **对假图像打分**: 将**生成**的假图像 `sr_t` 和对应的低分辨率图像 `lr_t` 输入 `Ds`。`Ds` 的目标是输出 0 (表示“虚假”)。计算 `Ds` 在假图像上的损失（例如，与标签0的二元交叉熵损失）。
    *   **更新Ds**: 将上述两个损失相加，然后进行反向传播，**只更新 `Ds` 的权重**。

4.  **训练时间判别器 (Dt)**:
    *   **对真实序列打分**: 将**真实**的连续三帧 `(hr_t-1, hr_t, hr_t+1)` 拼接后输入 `Dt`。`Dt` 的目标是输出 1 (表示“时间连贯的真实序列”)。计算 `Dt` 在真实序列上的损失。
    *   **对假序列打分**: 将**生成**的连续三帧 `(sr_t-1, sr_t, sr_t+1)` 拼接后输入 `Dt`。`Dt` 的目标是输出 0 (表示“时间不连贯或虚假的序列”)。计算 `Dt` 在假序列上的损失。
    *   **更新Dt**: 将这两个损失相加，进行反向传播，**只更新 `Dt` 的权重**。

> **注意**：`Ds` 和 `Dt` 的训练是独立进行的，你可以把它们放在同一个优化器里，也可以分开。关键是，在这一大步中，G的参数不发生改变。**而且Dt和Ds一样，是每一次迭代都训练的**，而不是“每有3张图片训练一次”。

#### **步骤 B：训练生成器 (Generator)**

在这一步，**两个判别器的权重是固定的（冻结的）**，我们只更新生成器 `G` 的权重。目标是让 `G` 生成的图像不仅清晰，而且能够骗过两个判别器。

1.  **生成假图像 (再次)**:
    *   将低分辨率图像 `(lr_t-1, lr_t, lr_t+1)` 再次输入生成器 `G`，得到 `(sr_t-1, sr_t, sr_t+1)`。

2.  **计算生成器的总损失 (Total Generator Loss)**:
    *   **内容损失 (Content Loss)**: 这是最基础的损失。计算生成的图像 `sr_t` 和真实的高分辨率图像 `hr_t` 之间的差异，通常用 L1 损失（`|sr_t - hr_t|`）。这保证了生成图像的内容是正确的。
    *   **对抗性损失 - 来自Ds (Adversarial Loss S)**: 将生成的 `sr_t` 和 `lr_t` 输入**固定的Ds**。`G` 的目标是让 `Ds` 认为这张图是真的（输出1）。所以，我们计算 `Ds` 的输出与标签 1 之间的损失。这个损失会驱动 `G` 生成空间上更逼真的细节。
    *   **对抗性损失 - 来自Dt (Adversarial Loss T)**: 将生成的序列 `(sr_t-1, sr_t, sr_t+1)` 输入**固定的Dt**。`G` 的目标是让 `Dt` 认为这个序列是真的（输出1）。我们计算 `Dt` 的输出与标签 1 之间的损失。这个损失会驱动 `G` 生成时间上更连贯、无闪烁的细节。

3.  **更新G**:
    *   将上述三种损失加权求和：`Total_G_Loss = λ_content * L_content + λ_adv_s * L_adv_s + λ_adv_t * L_adv_t`。
    *   对这个总损失进行反向传播，**只更新 `G` 的权重**。

## 记录

这个digital typhoon的数据集结构如下：
- **主目录**: `data/WP/` (西太平洋海域)
- **图像数据**: `data/WP/image/` 目录
- **元数据**: `data/WP/metadata/` 目录
- **辅助数据**: `data/WP/aux_data.csv` 和 `data/WP/metadata.json`

其中image目录下的组织方式为：
- 按年份+月份分组：`{YYYYMM}/` (如 `202107/` 表示2021年7月)
- 每个月份目录下包含多个h5文件
- h5文件命名格式：`YYYYMMDDTT-YYYY{Typhoon ID(当年第N号台风)}-HMW8-1.h5`
  - 例如：`2021071900-202107-HMW8-1.h5` 表示2021年7月19日00时的第7号台风数据

然后我们使用 test_data.py，拆解随机一个h5文件，得到：

```
root@autodl-container-2337448a2f-b25a3a94:~/autodl-tmp# python TempoGAN-Eddy/dataset/test_data.py data/WP/image/202107/2021071900-202107-HMW8-1.h5 
🌪️  Digital Typhoon H5文件结构查看器
==================================================

============================================================
文件路径: data/WP/image/202107/2021071900-202107-HMW8-1.h5
文件大小: 0.43 MB
============================================================
📁 / (Group)
   包含 1 个项目:
  📊 Infrared (Dataset)
     形状: (512, 512)
     数据类型: float64
     压缩: gzip
     样本数据 (前3x3):
     [[277.10538462 276.37615385 276.49769231]
 [277.22692308 276.01153846 276.25461538]
 [276.61923077 277.22692308 276.13307692]]
     属性: {'long_name': b'Brightness temperature', 'units': b'K (kelvin)'}
```

所以我们接下来的目标就是，直接把float64转成float32的形式，然后给Pytorch进行训练，然后我们接下来有这么几个目标：

## 目标

1. 检查一下现有的各个组件（dataset，train）是否可以适配我们的思路

2. 看看能不能直接走h5文件进行训练，输入的h5被提取出来数据，然后被dataset拼装成我们需要的形式。

3. 确定一下数据的folder结构是不是需要调整之类的。